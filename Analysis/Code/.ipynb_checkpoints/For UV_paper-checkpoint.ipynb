{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6bf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import subprocess \n",
    "import os\n",
    "import pybedtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02881000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/project/xtmp/hs239/UV_paper\n"
     ]
    }
   ],
   "source": [
    "cd /usr/project/xtmp/hs239/UV_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f9296b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Read in sites, input expected in BED format \n",
    "###Example sites read in here are EGR\n",
    "\n",
    "#path to file here\n",
    "filename=\"/usr/project/xtmp/hs239/UV_paper/archetype_site_Skin_intersect_EGR\"\n",
    "\n",
    "tf_sites=pd.read_csv(filename,sep=\"\\t\",header=None)\n",
    "\n",
    "##read in size of chromosomes,store it as a dictionary\n",
    "\n",
    "chrom_size=pd.read_csv(\"hg19.chrom.sizes\",sep=\"\\t\",header=None)\n",
    "chrom_size.columns=['chr','length']\n",
    "chrom_size=chrom_size.set_index('chr')['length'].to_dict()\n",
    "\n",
    "###Generate flanking regions. \n",
    "##To do this we just add +/- 1000bp to the sites called, but making sure that \n",
    "##the flanks are clipped at 0 (start of chr), or max(length of chromosome), mostly \n",
    "##to ensure that the downstream calls are okay\n",
    "\n",
    "temp_df=tf_sites\n",
    "temp_df['chr_length']=temp_df[0].apply(lambda x: chrom_size[x])\n",
    "temp_df['beg']=temp_df[1]-1000\n",
    "temp_df['fin']=temp_df[2]+1000\n",
    "temp_df['beg'].clip(lower=0,inplace=True)\n",
    "temp_df['fin'].clip(upper=temp_df['chr_length'],inplace=True)\n",
    "\n",
    "temp_df['beg']=temp_df['beg'].astype(int)\n",
    "temp_df['fin']=temp_df['fin'].astype(int)\n",
    "\n",
    "###########################################\n",
    "\n",
    "##NOTE: modify columns accordingly, you want to store 0,beg,fin and strand column t\n",
    "\n",
    "columns=columns=[0,'beg','fin',3,4,5,6,7]\n",
    "temp_df.to_csv(filename+\"_extended\",columns=columns,index=None,sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955aab3",
   "metadata": {},
   "source": [
    "You now have a bed file with flanking regions, the next step is to just add the sequences to this.\n",
    "\n",
    "\n",
    "The sites I used were hg19, so I'm using a hg19 reference. \n",
    "\n",
    "Importantly, mutations are in hg19, so any sites called in hg38 should probably first be liftOver to hg19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27b88bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate flanking sequences\n",
    "\n",
    "##this file is the file stored at the end of the module above\n",
    "file=filename+\"_extended\"\n",
    "\n",
    "##reference fasta file\n",
    "fasta=\"/home/home5/hs239/hg19.fa\"\n",
    "\n",
    "fasta_name=file+\".fa\"\n",
    "\n",
    "\n",
    "command1=\"bedtools getfasta -fi /home/home5/hs239/hg19.fa -bed \"+file+\" -tab > \"+fasta_name\n",
    "\n",
    "command2=\"paste \"+filename+\" \"+fasta_name+\" > \"+file+\"_sequence\"\n",
    "subprocess.call(command1,shell=True)\n",
    "subprocess.call(command2,shell=True)\n",
    "os.remove(fasta_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aba3c5",
   "metadata": {},
   "source": [
    "We now have sequences stored for the flanking regions of a given site. \n",
    "\n",
    "The bed file stores the coordinates for the flanks, and not the sites itself, but you can modify the first cell to also store the site location. I don't see a need to do this since the sites should be flank+/-1000 and hence recoverable, but the relevant modification would be columns=columns=[0,'beg','fin',3,4,5,6,7,1,2]. \n",
    "\n",
    "\n",
    "You just wanna make sure that the first 3 columns point to the flanks and not the sites, so that when bedtools looks for sequences it looks for the whole region. At this step the file look like this : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df8b3d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2</td>\n",
       "      <td>114341677</td>\n",
       "      <td>114341688</td>\n",
       "      <td>EGR</td>\n",
       "      <td>8.3475</td>\n",
       "      <td>+</td>\n",
       "      <td>EGR1_C2H2_1</td>\n",
       "      <td>11</td>\n",
       "      <td>chr2:114340677-114342688</td>\n",
       "      <td>ttttaatctggcaaccctaAAAGGCAAGAGCCAAAAATGCCGGAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2</td>\n",
       "      <td>114341626</td>\n",
       "      <td>114341637</td>\n",
       "      <td>EGR</td>\n",
       "      <td>10.5582</td>\n",
       "      <td>+</td>\n",
       "      <td>EGR4_C2H2_1</td>\n",
       "      <td>13</td>\n",
       "      <td>chr2:114340626-114342637</td>\n",
       "      <td>acgaaattattcgttgtttatctaaaattcaaactagctgggcatc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2</td>\n",
       "      <td>114341604</td>\n",
       "      <td>114341615</td>\n",
       "      <td>EGR</td>\n",
       "      <td>7.6202</td>\n",
       "      <td>+</td>\n",
       "      <td>EGR1_C2H2_1</td>\n",
       "      <td>8</td>\n",
       "      <td>chr2:114340604-114342615</td>\n",
       "      <td>aagcttgggaaatatttatgctacgaaattattcgttgtttatcta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>714110</td>\n",
       "      <td>714121</td>\n",
       "      <td>EGR</td>\n",
       "      <td>6.6799</td>\n",
       "      <td>+</td>\n",
       "      <td>EGR2_C2H2_1</td>\n",
       "      <td>8</td>\n",
       "      <td>chr1:713110-715121</td>\n",
       "      <td>cacggccagctaatttttgtattttttgtagagactgggtttcacc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>714138</td>\n",
       "      <td>714155</td>\n",
       "      <td>KLF/SP/2</td>\n",
       "      <td>8.9756</td>\n",
       "      <td>+</td>\n",
       "      <td>EGR1_HUMAN.H11MO.0.A</td>\n",
       "      <td>3</td>\n",
       "      <td>chr1:713138-715155</td>\n",
       "      <td>tagagactgggtttcaccatggccaggctggtctccaactcctgac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1          2         3        4  5                     6   7  \\\n",
       "0  chr2  114341677  114341688       EGR   8.3475  +           EGR1_C2H2_1  11   \n",
       "1  chr2  114341626  114341637       EGR  10.5582  +           EGR4_C2H2_1  13   \n",
       "2  chr2  114341604  114341615       EGR   7.6202  +           EGR1_C2H2_1   8   \n",
       "3  chr1     714110     714121       EGR   6.6799  +           EGR2_C2H2_1   8   \n",
       "4  chr1     714138     714155  KLF/SP/2   8.9756  +  EGR1_HUMAN.H11MO.0.A   3   \n",
       "\n",
       "                          8                                                  9  \n",
       "0  chr2:114340677-114342688  ttttaatctggcaaccctaAAAGGCAAGAGCCAAAAATGCCGGAGG...  \n",
       "1  chr2:114340626-114342637  acgaaattattcgttgtttatctaaaattcaaactagctgggcatc...  \n",
       "2  chr2:114340604-114342615  aagcttgggaaatatttatgctacgaaattattcgttgtttatcta...  \n",
       "3        chr1:713110-715121  cacggccagctaatttttgtattttttgtagagactgggtttcacc...  \n",
       "4        chr1:713138-715155  tagagactgggtttcaccatggccaggctggtctccaactcctgac...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=filename+\"_extended_sequence\"\n",
    "\n",
    "df=pd.read_csv(file,header=None,sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5777d0",
   "metadata": {},
   "source": [
    "This is also roughly the same file I gave you in an email to look for sequences in. \n",
    "\n",
    "\n",
    "\n",
    "So the next step would assume that we have generated the files you sent to me here. \n",
    "I'm using a random file amongst those as an input for the next step. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf3bcf",
   "metadata": {},
   "source": [
    "Now the intersection should be straightforward. \n",
    "\n",
    "The relevant mutation file is already processed and in the folder, so only needs a bedtools intersect. \n",
    "\n",
    "**Note** that currently the file will remove any duplicate counts (if a region is repeated twice), but if two regions overlap, there is a possibility that the same mutation is counted twice. We should discuss if this is something we want, I think we should be counting these multiple times like right now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e2c63a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "###read in flanks with nonconsensus locations\n",
    "non_consensus_site=\"EGR1_NonConsensus_promoter_10plus_bp_norepeats.bed\"\n",
    "mutation_file=\"skcm_mutations.bed\"\n",
    "\n",
    "command1=\"bedtools intersect -wa -wb -a \"+non_consensus_site+\" -b \"+ mutation_file +\" > \"+ non_consensus_site+\"_mutation_counts\"\n",
    "subprocess.call(command1,shell=True)\n",
    "\n",
    "###This part is to remove duplicates, and change column names to something one can interpret. \n",
    "###in case this file is being used in further bedtools operations, the header column might need to be dropped\n",
    "df = pd.read_csv(non_consensus_site+\"_mutation_counts\",sep=\"\\t\",header=None)\n",
    "df=df.drop_duplicates(subset=[0,1,2,4,5,6,7,8])\n",
    "df.to_csv(non_consensus_site+\"_mutation_counts\",sep=\"\\t\",header=None,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec04190",
   "metadata": {},
   "source": [
    "There are other files in this folder that should help with other parts of the analysis, like background mutation rates. But I thing the first step is to figure out what sites and regions we use. \n",
    "\n",
    "\n",
    "You might be able to see in the example here that 20bp regions generate very few mutations, so we'd need something else as the default for best results. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "29418dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(non_consensus_site+\"_mutation_counts\",sep=\"\\t\",header=None)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd87866",
   "metadata": {},
   "source": [
    "For reference, the \"EGR1_NonConsensus_promoter_10plus_bp_norepeats.bed\" file generates more mutations, as is expected. This might be what we'd need to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "73422efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9093"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('EGR1_NonConsensus_promoter_10plus_bp_norepeats.bed_mutation_counts',sep=\"\\t\",header=None)\n",
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
